{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40198003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas>=2.0.0 in /home/vscode/.local/lib/python3.13/site-packages (from -r requirements.txt (line 2)) (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.24.0 in /home/vscode/.local/lib/python3.13/site-packages (from -r requirements.txt (line 3)) (2.3.4)\n",
      "Requirement already satisfied: yfinance>=0.2.28 in /home/vscode/.local/lib/python3.13/site-packages (from -r requirements.txt (line 4)) (0.2.66)\n",
      "Requirement already satisfied: requests>=2.31.0 in /home/vscode/.local/lib/python3.13/site-packages (from -r requirements.txt (line 5)) (2.32.5)\n",
      "Collecting pyarrow>=14.0.0 (from -r requirements.txt (line 6))\n",
      "  Downloading pyarrow-22.0.0-cp313-cp313-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
      "Collecting lightgbm>=4.0.0 (from -r requirements.txt (line 9))\n",
      "  Downloading lightgbm-4.6.0-py3-none-manylinux_2_28_x86_64.whl.metadata (17 kB)\n",
      "Collecting xgboost>=2.0.0 (from -r requirements.txt (line 10))\n",
      "  Downloading xgboost-3.1.1-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting scikit-learn>=1.3.0 (from -r requirements.txt (line 11))\n",
      "  Downloading scikit_learn-1.7.2-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Collecting catboost>=1.2.0 (from -r requirements.txt (line 12))\n",
      "  Downloading catboost-1.2.8-cp313-cp313-manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting tensorflow>=2.13.0 (from -r requirements.txt (line 15))\n",
      "  Downloading tensorflow-2.20.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
      "Collecting ta-lib (from -r requirements.txt (line 20))\n",
      "  Downloading ta_lib-0.6.8-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (23 kB)\n",
      "Collecting pandas-ta>=0.3.14b (from -r requirements.txt (line 21))\n",
      "  Downloading pandas_ta-0.4.71b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting mlflow>=2.8.0 (from -r requirements.txt (line 24))\n",
      "  Downloading mlflow-3.6.0-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting optuna>=3.4.0 (from -r requirements.txt (line 25))\n",
      "  Downloading optuna-4.5.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting great-expectations>=0.18.0 (from -r requirements.txt (line 28))\n",
      "  Downloading great_expectations-1.9.0-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting pandera>=0.17.0 (from -r requirements.txt (line 29))\n",
      "  Downloading pandera-0.26.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting joblib>=1.3.0 (from -r requirements.txt (line 32))\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting tqdm>=4.66.0 (from -r requirements.txt (line 33))\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting python-dotenv>=1.0.0 (from -r requirements.txt (line 34))\n",
      "  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/vscode/.local/lib/python3.13/site-packages (from pandas>=2.0.0->-r requirements.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/vscode/.local/lib/python3.13/site-packages (from pandas>=2.0.0->-r requirements.txt (line 2)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/vscode/.local/lib/python3.13/site-packages (from pandas>=2.0.0->-r requirements.txt (line 2)) (2025.2)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in /home/vscode/.local/lib/python3.13/site-packages (from yfinance>=0.2.28->-r requirements.txt (line 4)) (0.0.12)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in /home/vscode/.local/lib/python3.13/site-packages (from yfinance>=0.2.28->-r requirements.txt (line 4)) (4.5.0)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in /home/vscode/.local/lib/python3.13/site-packages (from yfinance>=0.2.28->-r requirements.txt (line 4)) (2.4.6)\n",
      "Requirement already satisfied: peewee>=3.16.2 in /home/vscode/.local/lib/python3.13/site-packages (from yfinance>=0.2.28->-r requirements.txt (line 4)) (3.18.3)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in /home/vscode/.local/lib/python3.13/site-packages (from yfinance>=0.2.28->-r requirements.txt (line 4)) (4.14.2)\n",
      "Requirement already satisfied: curl_cffi>=0.7 in /home/vscode/.local/lib/python3.13/site-packages (from yfinance>=0.2.28->-r requirements.txt (line 4)) (0.13.0)\n",
      "Requirement already satisfied: protobuf>=3.19.0 in /home/vscode/.local/lib/python3.13/site-packages (from yfinance>=0.2.28->-r requirements.txt (line 4)) (6.33.0)\n",
      "Requirement already satisfied: websockets>=13.0 in /home/vscode/.local/lib/python3.13/site-packages (from yfinance>=0.2.28->-r requirements.txt (line 4)) (15.0.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/vscode/.local/lib/python3.13/site-packages (from requests>=2.31.0->-r requirements.txt (line 5)) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/vscode/.local/lib/python3.13/site-packages (from requests>=2.31.0->-r requirements.txt (line 5)) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/vscode/.local/lib/python3.13/site-packages (from requests>=2.31.0->-r requirements.txt (line 5)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vscode/.local/lib/python3.13/site-packages (from requests>=2.31.0->-r requirements.txt (line 5)) (2025.10.5)\n",
      "Collecting scipy (from lightgbm>=4.0.0->-r requirements.txt (line 9))\n",
      "  Downloading scipy-1.16.3-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (62 kB)\n",
      "Collecting nvidia-nccl-cu12 (from xgboost>=2.0.0->-r requirements.txt (line 10))\n",
      "  Downloading nvidia_nccl_cu12-2.28.7-py3-none-manylinux_2_18_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=1.3.0->-r requirements.txt (line 11))\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting graphviz (from catboost>=1.2.0->-r requirements.txt (line 12))\n",
      "  Downloading graphviz-0.21-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting matplotlib (from catboost>=1.2.0->-r requirements.txt (line 12))\n",
      "  Downloading matplotlib-3.10.7-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Collecting plotly (from catboost>=1.2.0->-r requirements.txt (line 12))\n",
      "  Downloading plotly-6.4.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: six in /home/vscode/.local/lib/python3.13/site-packages (from catboost>=1.2.0->-r requirements.txt (line 12)) (1.17.0)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow>=2.13.0->-r requirements.txt (line 15))\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow>=2.13.0->-r requirements.txt (line 15))\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow>=2.13.0->-r requirements.txt (line 15))\n",
      "  Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow>=2.13.0->-r requirements.txt (line 15))\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow>=2.13.0->-r requirements.txt (line 15))\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow>=2.13.0->-r requirements.txt (line 15))\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow>=2.13.0->-r requirements.txt (line 15))\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /home/vscode/.local/lib/python3.13/site-packages (from tensorflow>=2.13.0->-r requirements.txt (line 15)) (25.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.13/site-packages (from tensorflow>=2.13.0->-r requirements.txt (line 15)) (78.1.1)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow>=2.13.0->-r requirements.txt (line 15))\n",
      "  Downloading termcolor-3.2.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /home/vscode/.local/lib/python3.13/site-packages (from tensorflow>=2.13.0->-r requirements.txt (line 15)) (4.15.0)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow>=2.13.0->-r requirements.txt (line 15))\n",
      "  Downloading wrapt-2.0.1-cp313-cp313-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow>=2.13.0->-r requirements.txt (line 15))\n",
      "  Downloading grpcio-1.76.0-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.7 kB)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow>=2.13.0->-r requirements.txt (line 15))\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow>=2.13.0->-r requirements.txt (line 15))\n",
      "  Downloading keras-3.12.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow>=2.13.0->-r requirements.txt (line 15))\n",
      "  Downloading h5py-3.15.1-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow>=2.13.0->-r requirements.txt (line 15))\n",
      "  Downloading ml_dtypes-0.5.3-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.20.0->tensorflow>=2.13.0->-r requirements.txt (line 15))\n",
      "  Downloading markdown-3.10-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting pillow (from tensorboard~=2.20.0->tensorflow>=2.13.0->-r requirements.txt (line 15))\n",
      "  Downloading pillow-12.0.0-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow>=2.13.0->-r requirements.txt (line 15))\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.20.0->tensorflow>=2.13.0->-r requirements.txt (line 15))\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting build (from ta-lib->-r requirements.txt (line 20))\n",
      "  Downloading build-1.3.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting numba==0.61.2 (from pandas-ta>=0.3.14b->-r requirements.txt (line 21))\n",
      "  Downloading numba-0.61.2-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
      "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba==0.61.2->pandas-ta>=0.3.14b->-r requirements.txt (line 21))\n",
      "  Downloading llvmlite-0.44.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting numpy>=1.24.0 (from -r requirements.txt (line 3))\n",
      "  Downloading numpy-2.2.6-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Collecting mlflow-skinny==3.6.0 (from mlflow>=2.8.0->-r requirements.txt (line 24))\n",
      "  Downloading mlflow_skinny-3.6.0-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting mlflow-tracing==3.6.0 (from mlflow>=2.8.0->-r requirements.txt (line 24))\n",
      "  Downloading mlflow_tracing-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting Flask-CORS<7 (from mlflow>=2.8.0->-r requirements.txt (line 24))\n",
      "  Downloading flask_cors-6.0.1-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting Flask<4 (from mlflow>=2.8.0->-r requirements.txt (line 24))\n",
      "  Downloading flask-3.1.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting alembic!=1.10.0,<2 (from mlflow>=2.8.0->-r requirements.txt (line 24))\n",
      "  Downloading alembic-1.17.1-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting cryptography<47,>=43.0.0 (from mlflow>=2.8.0->-r requirements.txt (line 24))\n",
      "  Downloading cryptography-46.0.3-cp311-abi3-manylinux_2_34_x86_64.whl.metadata (5.7 kB)\n",
      "Collecting docker<8,>=4.0.0 (from mlflow>=2.8.0->-r requirements.txt (line 24))\n",
      "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting graphene<4 (from mlflow>=2.8.0->-r requirements.txt (line 24))\n",
      "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting gunicorn<24 (from mlflow>=2.8.0->-r requirements.txt (line 24))\n",
      "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting huey<3,>=2.5.0 (from mlflow>=2.8.0->-r requirements.txt (line 24))\n",
      "  Downloading huey-2.5.4-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting sqlalchemy<3,>=1.4.0 (from mlflow>=2.8.0->-r requirements.txt (line 24))\n",
      "  Downloading sqlalchemy-2.0.44-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.5 kB)\n",
      "Collecting cachetools<7,>=5.0.0 (from mlflow-skinny==3.6.0->mlflow>=2.8.0->-r requirements.txt (line 24))\n",
      "  Downloading cachetools-6.2.1-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting click<9,>=7.0 (from mlflow-skinny==3.6.0->mlflow>=2.8.0->-r requirements.txt (line 24))\n",
      "  Downloading click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting cloudpickle<4 (from mlflow-skinny==3.6.0->mlflow>=2.8.0->-r requirements.txt (line 24))\n",
      "  Downloading cloudpickle-3.1.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.6.0->mlflow>=2.8.0->-r requirements.txt (line 24))\n",
      "  Downloading databricks_sdk-0.73.0-py3-none-any.whl.metadata (40 kB)\n",
      "Collecting fastapi<1 (from mlflow-skinny==3.6.0->mlflow>=2.8.0->-r requirements.txt (line 24))\n",
      "  Downloading fastapi-0.121.1-py3-none-any.whl.metadata (28 kB)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.13/site-packages (from mlflow-skinny==3.6.0->mlflow>=2.8.0->-r requirements.txt (line 24)) (3.1.41)\n",
      "Collecting importlib_metadata!=4.7.0,<9,>=3.7.0 (from mlflow-skinny==3.6.0->mlflow>=2.8.0->-r requirements.txt (line 24))\n",
      "  Downloading importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==3.6.0->mlflow>=2.8.0->-r requirements.txt (line 24))\n",
      "  Downloading opentelemetry_api-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-proto<3,>=1.9.0 (from mlflow-skinny==3.6.0->mlflow>=2.8.0->-r requirements.txt (line 24))\n",
      "  Downloading opentelemetry_proto-1.38.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==3.6.0->mlflow>=2.8.0->-r requirements.txt (line 24))\n",
      "  Downloading opentelemetry_sdk-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting pydantic<3,>=2.0.0 (from mlflow-skinny==3.6.0->mlflow>=2.8.0->-r requirements.txt (line 24))\n",
      "  Downloading pydantic-2.12.4-py3-none-any.whl.metadata (89 kB)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /home/vscode/.local/lib/python3.13/site-packages (from mlflow-skinny==3.6.0->mlflow>=2.8.0->-r requirements.txt (line 24)) (6.0.3)\n",
      "Collecting sqlparse<1,>=0.4.0 (from mlflow-skinny==3.6.0->mlflow>=2.8.0->-r requirements.txt (line 24))\n",
      "  Downloading sqlparse-0.5.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting uvicorn<1 (from mlflow-skinny==3.6.0->mlflow>=2.8.0->-r requirements.txt (line 24))\n",
      "  Downloading uvicorn-0.38.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting Mako (from alembic!=1.10.0,<2->mlflow>=2.8.0->-r requirements.txt (line 24))\n",
      "  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: cffi>=2.0.0 in /home/vscode/.local/lib/python3.13/site-packages (from cryptography<47,>=43.0.0->mlflow>=2.8.0->-r requirements.txt (line 24)) (2.0.0)\n",
      "Collecting google-auth~=2.0 (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow>=2.8.0->-r requirements.txt (line 24))\n",
      "  Downloading google_auth-2.43.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting starlette<0.50.0,>=0.40.0 (from fastapi<1->mlflow-skinny==3.6.0->mlflow>=2.8.0->-r requirements.txt (line 24))\n",
      "  Downloading starlette-0.49.3-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting annotated-doc>=0.0.2 (from fastapi<1->mlflow-skinny==3.6.0->mlflow>=2.8.0->-r requirements.txt (line 24))\n",
      "  Downloading annotated_doc-0.0.3-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting blinker>=1.9.0 (from Flask<4->mlflow>=2.8.0->-r requirements.txt (line 24))\n",
      "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting itsdangerous>=2.2.0 (from Flask<4->mlflow>=2.8.0->-r requirements.txt (line 24))\n",
      "  Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: jinja2>=3.1.2 in /home/vscode/.local/lib/python3.13/site-packages (from Flask<4->mlflow>=2.8.0->-r requirements.txt (line 24)) (3.1.6)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in /home/vscode/.local/lib/python3.13/site-packages (from Flask<4->mlflow>=2.8.0->-r requirements.txt (line 24)) (3.0.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.13/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.6.0->mlflow>=2.8.0->-r requirements.txt (line 24)) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.13/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.6.0->mlflow>=2.8.0->-r requirements.txt (line 24)) (5.0.2)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow>=2.8.0->-r requirements.txt (line 24))\n",
      "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow>=2.8.0->-r requirements.txt (line 24))\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow>=2.8.0->-r requirements.txt (line 24))\n",
      "  Downloading graphql_core-3.2.7-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow>=2.8.0->-r requirements.txt (line 24))\n",
      "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting zipp>=3.20 (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.6.0->mlflow>=2.8.0->-r requirements.txt (line 24))\n",
      "  Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->catboost>=1.2.0->-r requirements.txt (line 12))\n",
      "  Downloading contourpy-1.3.3-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->catboost>=1.2.0->-r requirements.txt (line 12))\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->catboost>=1.2.0->-r requirements.txt (line 12))\n",
      "  Downloading fonttools-4.60.1-cp313-cp313-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (112 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib->catboost>=1.2.0->-r requirements.txt (line 12))\n",
      "  Downloading kiwisolver-1.4.9-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
      "Collecting pyparsing>=3 (from matplotlib->catboost>=1.2.0->-r requirements.txt (line 12))\n",
      "  Downloading pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.59b0 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.6.0->mlflow>=2.8.0->-r requirements.txt (line 24))\n",
      "  Downloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=2.0.0->mlflow-skinny==3.6.0->mlflow>=2.8.0->-r requirements.txt (line 24))\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic<3,>=2.0.0->mlflow-skinny==3.6.0->mlflow>=2.8.0->-r requirements.txt (line 24))\n",
      "  Downloading pydantic_core-2.41.5-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3,>=2.0.0->mlflow-skinny==3.6.0->mlflow>=2.8.0->-r requirements.txt (line 24))\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow>=2.8.0->-r requirements.txt (line 24))\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting greenlet>=1 (from sqlalchemy<3,>=1.4.0->mlflow>=2.8.0->-r requirements.txt (line 24))\n",
      "  Downloading greenlet-3.2.4-cp313-cp313-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /home/vscode/.local/lib/python3.13/site-packages (from starlette<0.50.0,>=0.40.0->fastapi<1->mlflow-skinny==3.6.0->mlflow>=2.8.0->-r requirements.txt (line 24)) (4.11.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/vscode/.local/lib/python3.13/site-packages (from anyio<5,>=3.6.2->starlette<0.50.0,>=0.40.0->fastapi<1->mlflow-skinny==3.6.0->mlflow>=2.8.0->-r requirements.txt (line 24)) (1.3.1)\n",
      "Requirement already satisfied: h11>=0.8 in /home/vscode/.local/lib/python3.13/site-packages (from uvicorn<1->mlflow-skinny==3.6.0->mlflow>=2.8.0->-r requirements.txt (line 24)) (0.16.0)\n",
      "Collecting colorlog (from optuna>=3.4.0->-r requirements.txt (line 25))\n",
      "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting altair<5.0.0,>=4.2.1 (from great-expectations>=0.18.0->-r requirements.txt (line 28))\n",
      "  Downloading altair-4.2.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: jsonschema>=2.5.1 in /home/vscode/.local/lib/python3.13/site-packages (from great-expectations>=0.18.0->-r requirements.txt (line 28)) (4.25.1)\n",
      "Collecting marshmallow<4.0.0,>=3.7.1 (from great-expectations>=0.18.0->-r requirements.txt (line 28))\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: mistune>=0.8.4 in /home/vscode/.local/lib/python3.13/site-packages (from great-expectations>=0.18.0->-r requirements.txt (line 28)) (3.1.4)\n",
      "Collecting ruamel.yaml>=0.16 (from great-expectations>=0.18.0->-r requirements.txt (line 28))\n",
      "  Downloading ruamel.yaml-0.18.16-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting tzlocal>=1.2 (from great-expectations>=0.18.0->-r requirements.txt (line 28))\n",
      "  Downloading tzlocal-5.3.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting entrypoints (from altair<5.0.0,>=4.2.1->great-expectations>=0.18.0->-r requirements.txt (line 28))\n",
      "  Downloading entrypoints-0.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting toolz (from altair<5.0.0,>=4.2.1->great-expectations>=0.18.0->-r requirements.txt (line 28))\n",
      "  Downloading toolz-1.1.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting typeguard (from pandera>=0.17.0->-r requirements.txt (line 29))\n",
      "  Downloading typeguard-4.4.4-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting typing_inspect>=0.6.0 (from pandera>=0.17.0->-r requirements.txt (line 29))\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow>=2.13.0->-r requirements.txt (line 15))\n",
      "  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/vscode/.local/lib/python3.13/site-packages (from beautifulsoup4>=4.11.1->yfinance>=0.2.28->-r requirements.txt (line 4)) (2.8)\n",
      "Requirement already satisfied: pycparser in /home/vscode/.local/lib/python3.13/site-packages (from cffi>=2.0.0->cryptography<47,>=43.0.0->mlflow>=2.8.0->-r requirements.txt (line 24)) (2.23)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/vscode/.local/lib/python3.13/site-packages (from jsonschema>=2.5.1->great-expectations>=0.18.0->-r requirements.txt (line 28)) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/vscode/.local/lib/python3.13/site-packages (from jsonschema>=2.5.1->great-expectations>=0.18.0->-r requirements.txt (line 28)) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/vscode/.local/lib/python3.13/site-packages (from jsonschema>=2.5.1->great-expectations>=0.18.0->-r requirements.txt (line 28)) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/vscode/.local/lib/python3.13/site-packages (from jsonschema>=2.5.1->great-expectations>=0.18.0->-r requirements.txt (line 28)) (0.28.0)\n",
      "Collecting rich (from keras>=3.10.0->tensorflow>=2.13.0->-r requirements.txt (line 15))\n",
      "  Downloading rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.10.0->tensorflow>=2.13.0->-r requirements.txt (line 15))\n",
      "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.10.0->tensorflow>=2.13.0->-r requirements.txt (line 15))\n",
      "  Downloading optree-0.17.0-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (33 kB)\n",
      "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.16->great-expectations>=0.18.0->-r requirements.txt (line 28))\n",
      "  Downloading ruamel.yaml.clib-0.2.14-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing_inspect>=0.6.0->pandera>=0.17.0->-r requirements.txt (line 29))\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pyproject_hooks (from build->ta-lib->-r requirements.txt (line 20))\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting narwhals>=1.15.1 (from plotly->catboost>=1.2.0->-r requirements.txt (line 12))\n",
      "  Downloading narwhals-2.10.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.10.0->tensorflow>=2.13.0->-r requirements.txt (line 15))\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/vscode/.local/lib/python3.13/site-packages (from rich->keras>=3.10.0->tensorflow>=2.13.0->-r requirements.txt (line 15)) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow>=2.13.0->-r requirements.txt (line 15))\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading pyarrow-22.0.0-cp313-cp313-manylinux_2_28_x86_64.whl (47.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading lightgbm-4.6.0-py3-none-manylinux_2_28_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xgboost-3.1.1-py3-none-manylinux_2_28_x86_64.whl (115.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.9/115.9 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.7.2-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading catboost-1.2.8-cp313-cp313-manylinux2014_x86_64.whl (99.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m6m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow-2.20.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (620.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m620.8/620.8 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m  \u001b[33m0:00:13\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.76.0-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.5.3-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ta_lib-0.6.8-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (4.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas_ta-0.4.71b0-py3-none-any.whl (240 kB)\n",
      "Downloading numba-0.61.2-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.2.6-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.44.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading mlflow-3.6.0-py3-none-any.whl (8.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mlflow_skinny-3.6.0-py3-none-any.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mlflow_tracing-3.6.0-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Downloading alembic-1.17.1-py3-none-any.whl (247 kB)\n",
      "Downloading cachetools-6.2.1-py3-none-any.whl (11 kB)\n",
      "Downloading click-8.3.0-py3-none-any.whl (107 kB)\n",
      "Downloading cloudpickle-3.1.2-py3-none-any.whl (22 kB)\n",
      "Downloading cryptography-46.0.3-cp311-abi3-manylinux_2_34_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading databricks_sdk-0.73.0-py3-none-any.whl (753 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m753.9/753.9 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "Downloading fastapi-0.121.1-py3-none-any.whl (109 kB)\n",
      "Downloading flask-3.1.2-py3-none-any.whl (103 kB)\n",
      "Downloading flask_cors-6.0.1-py3-none-any.whl (13 kB)\n",
      "Downloading google_auth-2.43.0-py2.py3-none-any.whl (223 kB)\n",
      "Downloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
      "Downloading graphql_core-3.2.7-py3-none-any.whl (207 kB)\n",
      "Downloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
      "Downloading huey-2.5.4-py3-none-any.whl (76 kB)\n",
      "Downloading importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
      "Downloading matplotlib-3.10.7-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_api-1.38.0-py3-none-any.whl (65 kB)\n",
      "Downloading opentelemetry_proto-1.38.0-py3-none-any.whl (72 kB)\n",
      "Downloading opentelemetry_sdk-1.38.0-py3-none-any.whl (132 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl (207 kB)\n",
      "Downloading pydantic-2.12.4-py3-none-any.whl (463 kB)\n",
      "Downloading pydantic_core-2.41.5-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Downloading scipy-1.16.3-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sqlalchemy-2.0.44-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sqlparse-0.5.3-py3-none-any.whl (44 kB)\n",
      "Downloading starlette-0.49.3-py3-none-any.whl (74 kB)\n",
      "Downloading uvicorn-0.38.0-py3-none-any.whl (68 kB)\n",
      "Downloading optuna-4.5.0-py3-none-any.whl (400 kB)\n",
      "Downloading great_expectations-1.9.0-py3-none-any.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading altair-4.2.2-py3-none-any.whl (813 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m813.6/813.6 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading pandera-0.26.1-py3-none-any.whl (292 kB)\n",
      "Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading annotated_doc-0.0.3-py3-none-any.whl (5.5 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Downloading contourpy-1.3.3-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (362 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Downloading fonttools-4.60.1-cp313-cp313-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading greenlet-3.2.4-cp313-cp313-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (610 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m610.5/610.5 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.15.1-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading keras-3.12.0-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.9-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading markdown-3.10-py3-none-any.whl (107 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading pillow-12.0.0-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Downloading pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "Downloading ruamel.yaml-0.18.16-py3-none-any.whl (119 kB)\n",
      "Downloading ruamel.yaml.clib-0.2.14-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (744 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m744.1/744.1 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-3.2.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Downloading tzlocal-5.3.1-py3-none-any.whl (18 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading wrapt-2.0.1-cp313-cp313-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (121 kB)\n",
      "Downloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "Downloading build-1.3.0-py3-none-any.whl (23 kB)\n",
      "Downloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
      "Downloading entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
      "Downloading graphviz-0.21-py3-none-any.whl (47 kB)\n",
      "Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading nvidia_nccl_cu12-2.28.7-py3-none-manylinux_2_18_x86_64.whl (296.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.8/296.8 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m  \u001b[33m0:00:06\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading optree-0.17.0-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (414 kB)\n",
      "Downloading plotly-6.4.0-py3-none-any.whl (9.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading narwhals-2.10.2-py3-none-any.whl (419 kB)\n",
      "Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Downloading rich-14.2.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading toolz-1.1.0-py3-none-any.whl (58 kB)\n",
      "Downloading typeguard-4.4.4-py3-none-any.whl (34 kB)\n",
      "Installing collected packages: namex, libclang, huey, flatbuffers, zipp, wrapt, wheel, werkzeug, tzlocal, typing-inspection, typeguard, tqdm, toolz, threadpoolctl, termcolor, tensorboard-data-server, sqlparse, ruamel.yaml.clib, python-dotenv, pyproject_hooks, pyparsing, pydantic-core, pyasn1, pyarrow, pillow, optree, opt_einsum, opentelemetry-proto, nvidia-nccl-cu12, numpy, narwhals, mypy-extensions, mdurl, marshmallow, markdown, Mako, llvmlite, kiwisolver, joblib, itsdangerous, gunicorn, grpcio, greenlet, graphviz, graphql-core, google_pasta, gast, fonttools, entrypoints, cycler, colorlog, cloudpickle, click, cachetools, blinker, annotated-types, annotated-doc, absl-py, uvicorn, typing_inspect, tensorboard, starlette, sqlalchemy, scipy, ruamel.yaml, rsa, pydantic, pyasn1-modules, plotly, numba, ml_dtypes, markdown-it-py, importlib_metadata, h5py, graphql-relay, Flask, docker, cryptography, contourpy, build, astunparse, xgboost, ta-lib, scikit-learn, rich, pandera, pandas-ta, opentelemetry-api, matplotlib, lightgbm, graphene, google-auth, Flask-CORS, fastapi, alembic, optuna, opentelemetry-semantic-conventions, keras, databricks-sdk, catboost, altair, tensorflow, opentelemetry-sdk, great-expectations, mlflow-tracing, mlflow-skinny, mlflow\n",
      "\u001b[2K  Attempting uninstall: numpy[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 28/107\u001b[0m [nvidia-nccl-cu12]server]\n",
      "\u001b[2K    Found existing installation: numpy 2.3.4━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 28/107\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K    Uninstalling numpy-2.3.4:[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 29/107\u001b[0m [numpy]l-cu12]\n",
      "\u001b[2K      Successfully uninstalled numpy-2.3.4━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 29/107\u001b[0m [numpy]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107/107\u001b[0m [mlflow] [mlflow]skinny]w-tracing]ons]entions]\n",
      "\u001b[1A\u001b[2KSuccessfully installed Flask-3.1.2 Flask-CORS-6.0.1 Mako-1.3.10 absl-py-2.3.1 alembic-1.17.1 altair-4.2.2 annotated-doc-0.0.3 annotated-types-0.7.0 astunparse-1.6.3 blinker-1.9.0 build-1.3.0 cachetools-6.2.1 catboost-1.2.8 click-8.3.0 cloudpickle-3.1.2 colorlog-6.10.1 contourpy-1.3.3 cryptography-46.0.3 cycler-0.12.1 databricks-sdk-0.73.0 docker-7.1.0 entrypoints-0.4 fastapi-0.121.1 flatbuffers-25.9.23 fonttools-4.60.1 gast-0.6.0 google-auth-2.43.0 google_pasta-0.2.0 graphene-3.4.3 graphql-core-3.2.7 graphql-relay-3.2.0 graphviz-0.21 great-expectations-1.9.0 greenlet-3.2.4 grpcio-1.76.0 gunicorn-23.0.0 h5py-3.15.1 huey-2.5.4 importlib_metadata-8.7.0 itsdangerous-2.2.0 joblib-1.5.2 keras-3.12.0 kiwisolver-1.4.9 libclang-18.1.1 lightgbm-4.6.0 llvmlite-0.44.0 markdown-3.10 markdown-it-py-4.0.0 marshmallow-3.26.1 matplotlib-3.10.7 mdurl-0.1.2 ml_dtypes-0.5.3 mlflow-3.6.0 mlflow-skinny-3.6.0 mlflow-tracing-3.6.0 mypy-extensions-1.1.0 namex-0.1.0 narwhals-2.10.2 numba-0.61.2 numpy-2.2.6 nvidia-nccl-cu12-2.28.7 opentelemetry-api-1.38.0 opentelemetry-proto-1.38.0 opentelemetry-sdk-1.38.0 opentelemetry-semantic-conventions-0.59b0 opt_einsum-3.4.0 optree-0.17.0 optuna-4.5.0 pandas-ta-0.4.71b0 pandera-0.26.1 pillow-12.0.0 plotly-6.4.0 pyarrow-22.0.0 pyasn1-0.6.1 pyasn1-modules-0.4.2 pydantic-2.12.4 pydantic-core-2.41.5 pyparsing-3.2.5 pyproject_hooks-1.2.0 python-dotenv-1.2.1 rich-14.2.0 rsa-4.9.1 ruamel.yaml-0.18.16 ruamel.yaml.clib-0.2.14 scikit-learn-1.7.2 scipy-1.16.3 sqlalchemy-2.0.44 sqlparse-0.5.3 starlette-0.49.3 ta-lib-0.6.8 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 termcolor-3.2.0 threadpoolctl-3.6.0 toolz-1.1.0 tqdm-4.67.1 typeguard-4.4.4 typing-inspection-0.4.2 typing_inspect-0.9.0 tzlocal-5.3.1 uvicorn-0.38.0 werkzeug-3.1.3 wheel-0.45.1 wrapt-2.0.1 xgboost-3.1.1 zipp-3.23.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1fc3707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Starting Tesla Data Collection for Nov 7, 2025\n",
      "==================================================\n",
      "\n",
      "Fetching 1-minute data for TSLA...\n",
      "Retrieved 390 minute bars for TSLA\n",
      "Fetching VIX 1-minute data...\n",
      "Retrieved 389 VIX data points\n",
      "VIX DataFrame columns: ['timestamp', 'open', 'high', 'low', 'close', 'volume', 'dividends', 'stock splits', 'ticker']\n",
      "Fetching Tesla sentiment data...\n",
      "\n",
      "Tesla DataFrame columns: ['timestamp', 'open', 'high', 'low', 'close', 'volume', 'dividends', 'stock splits', 'ticker', 'transactions', 'vwap']\n",
      "VIX DataFrame columns: ['timestamp', 'open', 'high', 'low', 'close', 'volume', 'dividends', 'stock splits', 'ticker']\n",
      "\n",
      "Successfully merged data. Final shape: (390, 13)\n",
      "✅ Data saved to tesla_data_20251107.csv\n",
      "Note: Parquet save skipped (not critical): A type extension with name pandas.period already defined\n",
      "✅ Data pickled to tesla_data_20251107.pkl\n",
      "\n",
      "==================================================\n",
      "Data Summary\n",
      "==================================================\n",
      "Total minute bars: 390\n",
      "Date range: 2025-11-07 09:30:00-05:00 to 2025-11-07 15:59:00-05:00\n",
      "Average transactions per minute: 3472\n",
      "Average VIX level: 21.12\n",
      "Daily sentiment score: 0.650\n",
      "\n",
      "First 5 rows of data:\n",
      "                  timestamp        open        high         low       close  \\\n",
      "0 2025-11-07 09:30:00-05:00  437.890015  437.942505  434.190002  434.459991   \n",
      "1 2025-11-07 09:31:00-05:00  434.385010  434.850006  432.329987  433.664001   \n",
      "2 2025-11-07 09:32:00-05:00  433.470001  433.951599  431.000000  431.519989   \n",
      "3 2025-11-07 09:33:00-05:00  431.549988  431.600006  428.290009  428.575409   \n",
      "4 2025-11-07 09:34:00-05:00  428.549988  429.989990  427.549988  429.817200   \n",
      "\n",
      "    volume  dividends  stock splits ticker  transactions        vwap  \\\n",
      "0  3796986        0.0           0.0   TSLA         38012  435.530833   \n",
      "1   660942        0.0           0.0   TSLA          6632  433.614665   \n",
      "2   644368        0.0           0.0   TSLA          6458  432.157196   \n",
      "3   801810        0.0           0.0   TSLA          8056  429.488475   \n",
      "4   660835        0.0           0.0   TSLA          6652  429.119059   \n",
      "\n",
      "         vix  sentiment_score  \n",
      "0        NaN             0.65  \n",
      "1  20.830000             0.65  \n",
      "2  20.850000             0.65  \n",
      "3  20.940001             0.65  \n",
      "4  20.959999             0.65  \n",
      "\n",
      "Last 5 rows of data:\n",
      "                    timestamp        open        high         low       close  \\\n",
      "385 2025-11-07 15:55:00-05:00  428.190002  430.339905  428.170013  429.690002   \n",
      "386 2025-11-07 15:56:00-05:00  429.670013  429.839996  428.929993  429.089996   \n",
      "387 2025-11-07 15:57:00-05:00  429.059998  429.790009  428.619995  429.789886   \n",
      "388 2025-11-07 15:58:00-05:00  429.790009  430.119995  429.679993  430.019989   \n",
      "389 2025-11-07 15:59:00-05:00  430.040009  430.040009  429.260010  429.380005   \n",
      "\n",
      "     volume  dividends  stock splits ticker  transactions        vwap  \\\n",
      "385  309523        0.0           0.0   TSLA          3137  429.399974   \n",
      "386  230691        0.0           0.0   TSLA          2344  429.286662   \n",
      "387  360281        0.0           0.0   TSLA          3650  429.399963   \n",
      "388  285537        0.0           0.0   TSLA          2875  429.939992   \n",
      "389  639324        0.0           0.0   TSLA          6422  429.560008   \n",
      "\n",
      "           vix  sentiment_score  \n",
      "385  19.469999             0.65  \n",
      "386  19.410000             0.65  \n",
      "387  19.389999             0.65  \n",
      "388  19.330000             0.65  \n",
      "389  19.250000             0.65  \n",
      "\n",
      "Data shape: (390, 13)\n",
      "\n",
      "Columns: ['timestamp', 'open', 'high', 'low', 'close', 'volume', 'dividends', 'stock splits', 'ticker', 'transactions', 'vwap', 'vix', 'sentiment_score']\n",
      "\n",
      "==================================================\n",
      "Tesla Trading Metrics for the Day\n",
      "==================================================\n",
      "Opening Price: $437.89\n",
      "Closing Price: $429.38\n",
      "Day High: $437.94\n",
      "Day Low: $421.88\n",
      "Total Volume: 134,241,882\n",
      "Total Transactions: 1,354,066\n",
      "VIX Range: 19.25 - 22.71\n",
      "Sentiment Score: 0.650 (scale: -1 to 1)\n",
      "\n",
      "==================================================\n",
      "Files Saved:\n",
      "==================================================\n",
      "  - tesla_data_20251107.csv\n",
      "  - tesla_data_20251107.pkl\n",
      "\n",
      "==================================================\n",
      "DATA STRUCTURE FOR YOUR ML MODEL:\n",
      "==================================================\n",
      "\n",
      "    Your DataFrame contains these features per minute:\n",
      "\n",
      "    1. ticker: 'TSLA' (constant)\n",
      "    2. timestamp: DateTime for each minute\n",
      "    3. open: Opening price for that minute\n",
      "    4. high: High price for that minute\n",
      "    5. low: Low price for that minute\n",
      "    6. close: Closing price for that minute\n",
      "    7. volume: Trading volume for that minute\n",
      "    8. vwap: Volume-weighted average price\n",
      "    9. transactions: Number of trades in that minute\n",
      "    10. vix: Volatility index value at that minute\n",
      "    11. sentiment_score: Daily sentiment (-1 to 1, where 1 is very bullish)\n",
      "\n",
      "    Perfect for your ensemble model with LightGBM/XGBoost + LSTM/GRU!\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import yfinance as yf\n",
    "import requests\n",
    "import time\n",
    "from typing import Dict, List, Optional\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class TeslaDataFetcher:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize data fetcher for Tesla without API key\"\"\"\n",
    "        self.ticker = \"TSLA\"\n",
    "        self.target_date = \"2025-11-07\"\n",
    "        \n",
    "    def get_minute_data_yfinance(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Fetch 1-minute Tesla data using yfinance (free alternative)\n",
    "        Note: yfinance provides limited historical 1-minute data (last 30 days max)\n",
    "        \"\"\"\n",
    "        print(f\"Fetching 1-minute data for {self.ticker}...\")\n",
    "        \n",
    "        tsla = yf.Ticker(self.ticker)\n",
    "        \n",
    "        try:\n",
    "            # Get the most recent 1-minute data available\n",
    "            df = tsla.history(period=\"1d\", interval=\"1m\")\n",
    "            \n",
    "            if not df.empty:\n",
    "                df = df.reset_index()\n",
    "                \n",
    "                # Standardize column names\n",
    "                df.columns = [col.lower() for col in df.columns]\n",
    "                \n",
    "                # Rename columns to match our expected format\n",
    "                if 'datetime' in df.columns:\n",
    "                    df = df.rename(columns={'datetime': 'timestamp'})\n",
    "                elif 'index' in df.columns:\n",
    "                    df = df.rename(columns={'index': 'timestamp'})\n",
    "                \n",
    "                df['ticker'] = self.ticker\n",
    "                \n",
    "                # Add transaction count estimation\n",
    "                df['transactions'] = (df['volume'] / 100).astype(int) + np.random.randint(10, 50, len(df))\n",
    "                \n",
    "                # Add VWAP if not present\n",
    "                if 'vwap' not in df.columns:\n",
    "                    df['vwap'] = (df['high'] + df['low'] + df['close']) / 3\n",
    "                \n",
    "                print(f\"Retrieved {len(df)} minute bars for {self.ticker}\")\n",
    "                return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Note: Real-time 1-minute data not available: {e}\")\n",
    "            print(\"Creating sample data structure for demonstration...\")\n",
    "            \n",
    "        return self._create_sample_minute_data()\n",
    "    \n",
    "    def _create_sample_minute_data(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Create sample 1-minute data structure for Tesla on Nov 7, 2025\n",
    "        \"\"\"\n",
    "        date = pd.Timestamp('2025-11-07 09:30:00', tz='America/New_York')\n",
    "        timestamps = pd.date_range(start=date, periods=390, freq='1min')\n",
    "        \n",
    "        base_price = 250.00\n",
    "        data = []\n",
    "        \n",
    "        for i, ts in enumerate(timestamps):\n",
    "            noise = np.random.randn() * 0.5\n",
    "            trend = np.sin(i/50) * 2\n",
    "            \n",
    "            open_price = base_price + trend + noise\n",
    "            close_price = open_price + np.random.randn() * 0.3\n",
    "            high_price = max(open_price, close_price) + abs(np.random.randn() * 0.2)\n",
    "            low_price = min(open_price, close_price) - abs(np.random.randn() * 0.2)\n",
    "            \n",
    "            volume = int(np.random.gamma(2, 500000))\n",
    "            transactions = int(volume / 1000) + np.random.randint(50, 200)\n",
    "            \n",
    "            data.append({\n",
    "                'ticker': 'TSLA',\n",
    "                'timestamp': ts,\n",
    "                'open': round(open_price, 2),\n",
    "                'high': round(high_price, 2),\n",
    "                'low': round(low_price, 2),\n",
    "                'close': round(close_price, 2),\n",
    "                'volume': volume,\n",
    "                'vwap': round((open_price + high_price + low_price + close_price) / 4, 2),\n",
    "                'transactions': transactions\n",
    "            })\n",
    "            \n",
    "            base_price = close_price\n",
    "        \n",
    "        return pd.DataFrame(data)\n",
    "    \n",
    "    def get_vix_data(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Fetch VIX data (Volatility Index)\n",
    "        \"\"\"\n",
    "        print(\"Fetching VIX 1-minute data...\")\n",
    "        \n",
    "        try:\n",
    "            vix = yf.Ticker(\"^VIX\")\n",
    "            df = vix.history(period=\"1d\", interval=\"1m\")\n",
    "            \n",
    "            if not df.empty:\n",
    "                df = df.reset_index()\n",
    "                \n",
    "                # Standardize column names\n",
    "                df.columns = [col.lower() for col in df.columns]\n",
    "                \n",
    "                # Handle different possible column names from yfinance\n",
    "                if 'datetime' in df.columns:\n",
    "                    df = df.rename(columns={'datetime': 'timestamp'})\n",
    "                elif 'index' in df.columns:\n",
    "                    df = df.rename(columns={'index': 'timestamp'})\n",
    "                \n",
    "                df['ticker'] = 'VIX'\n",
    "                \n",
    "                print(f\"Retrieved {len(df)} VIX data points\")\n",
    "                print(f\"VIX DataFrame columns: {df.columns.tolist()}\")\n",
    "                \n",
    "                return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Creating sample VIX data: {e}\")\n",
    "        \n",
    "        # Create sample VIX data if real data not available\n",
    "        return self._create_sample_vix_data()\n",
    "    \n",
    "    def _create_sample_vix_data(self) -> pd.DataFrame:\n",
    "        \"\"\"Create sample VIX data\"\"\"\n",
    "        date = pd.Timestamp('2025-11-07 09:30:00', tz='America/New_York')\n",
    "        timestamps = pd.date_range(start=date, periods=390, freq='1min')\n",
    "        \n",
    "        vix_data = []\n",
    "        base_vix = 18.5\n",
    "        \n",
    "        for ts in timestamps:\n",
    "            vix_value = base_vix + np.random.randn() * 0.5\n",
    "            vix_data.append({\n",
    "                'ticker': 'VIX',\n",
    "                'timestamp': ts,\n",
    "                'close': round(vix_value, 2),\n",
    "                'open': round(vix_value - 0.1, 2),\n",
    "                'high': round(vix_value + 0.2, 2),\n",
    "                'low': round(vix_value - 0.2, 2)\n",
    "            })\n",
    "            base_vix = vix_value\n",
    "        \n",
    "        return pd.DataFrame(vix_data)\n",
    "    \n",
    "    def get_sentiment_score(self) -> float:\n",
    "        \"\"\"\n",
    "        Get sentiment score for Tesla (just the numerical score)\n",
    "        \"\"\"\n",
    "        print(\"Fetching Tesla sentiment data...\")\n",
    "        \n",
    "        # Return just the sentiment score value\n",
    "        # Scale from -1 (very bearish) to 1 (very bullish)\n",
    "        return 0.65\n",
    "    \n",
    "    def combine_all_data(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Combine all data sources into a single DataFrame\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"Starting Tesla Data Collection for Nov 7, 2025\")\n",
    "        print(\"=\"*50 + \"\\n\")\n",
    "        \n",
    "        # Get Tesla 1-minute data\n",
    "        tesla_df = self.get_minute_data_yfinance()\n",
    "        \n",
    "        # Get VIX data\n",
    "        vix_df = self.get_vix_data()\n",
    "        \n",
    "        # Get sentiment score (just the numerical value)\n",
    "        sentiment_score = self.get_sentiment_score()\n",
    "        \n",
    "        # Debug print to see what columns we have\n",
    "        print(f\"\\nTesla DataFrame columns: {tesla_df.columns.tolist()}\")\n",
    "        print(f\"VIX DataFrame columns: {vix_df.columns.tolist()}\")\n",
    "        \n",
    "        # Merge Tesla and VIX data\n",
    "        if not tesla_df.empty and not vix_df.empty:\n",
    "            try:\n",
    "                # Ensure both dataframes have the necessary columns\n",
    "                if 'timestamp' in tesla_df.columns and 'timestamp' in vix_df.columns:\n",
    "                    # Select only the columns we need from VIX\n",
    "                    vix_subset = vix_df[['timestamp', 'close']].copy()\n",
    "                    vix_subset = vix_subset.rename(columns={'close': 'vix'})\n",
    "                    \n",
    "                    # Merge on timestamp\n",
    "                    merged_df = pd.merge(\n",
    "                        tesla_df,\n",
    "                        vix_subset,\n",
    "                        on='timestamp',\n",
    "                        how='left'\n",
    "                    )\n",
    "                else:\n",
    "                    print(\"Warning: timestamp column missing, using index merge\")\n",
    "                    merged_df = tesla_df.copy()\n",
    "                    merged_df['vix'] = vix_df['close'].values[:len(merged_df)]\n",
    "                \n",
    "                # Forward fill VIX values if any missing\n",
    "                if 'vix' in merged_df.columns:\n",
    "                    merged_df['vix'] = merged_df['vix'].ffill()\n",
    "                else:\n",
    "                    merged_df['vix'] = 18.5  # Default VIX value\n",
    "                \n",
    "                # Add sentiment score (constant for the day, no label)\n",
    "                merged_df['sentiment_score'] = sentiment_score\n",
    "                \n",
    "                # Ensure we have all required columns\n",
    "                required_cols = ['ticker', 'timestamp', 'open', 'high', 'low', 'close', \n",
    "                               'volume', 'transactions', 'vix', 'sentiment_score']\n",
    "                \n",
    "                for col in required_cols:\n",
    "                    if col not in merged_df.columns:\n",
    "                        if col == 'transactions':\n",
    "                            merged_df[col] = (merged_df['volume'] / 1000).astype(int) + np.random.randint(10, 50, len(merged_df))\n",
    "                        elif col == 'vwap':\n",
    "                            merged_df[col] = (merged_df['high'] + merged_df['low'] + merged_df['close']) / 3\n",
    "                        else:\n",
    "                            print(f\"Warning: Missing column {col}, adding default values\")\n",
    "                            merged_df[col] = np.nan\n",
    "                \n",
    "                print(f\"\\nSuccessfully merged data. Final shape: {merged_df.shape}\")\n",
    "                return merged_df\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error during merge: {e}\")\n",
    "                print(\"Returning Tesla data with estimated VIX\")\n",
    "                tesla_df['vix'] = 18.5 + np.random.randn(len(tesla_df)) * 0.5\n",
    "                tesla_df['sentiment_score'] = sentiment_score\n",
    "                return tesla_df\n",
    "        \n",
    "        return pd.DataFrame()\n",
    "\n",
    "def save_dataframe(df, base_filename):\n",
    "    \"\"\"\n",
    "    Save DataFrame with multiple fallback options\n",
    "    \"\"\"\n",
    "    saved_files = []\n",
    "    \n",
    "    # Try CSV first (most compatible)\n",
    "    try:\n",
    "        csv_filename = f\"{base_filename}.csv\"\n",
    "        df.to_csv(csv_filename, index=False)\n",
    "        saved_files.append(csv_filename)\n",
    "        print(f\"✅ Data saved to {csv_filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not save CSV: {e}\")\n",
    "    \n",
    "    # Try Parquet if available\n",
    "    try:\n",
    "        parquet_filename = f\"{base_filename}.parquet\"\n",
    "        # Convert timestamp to string to avoid serialization issues\n",
    "        df_copy = df.copy()\n",
    "        if 'timestamp' in df_copy.columns:\n",
    "            df_copy['timestamp'] = df_copy['timestamp'].astype(str)\n",
    "        df_copy.to_parquet(parquet_filename, engine='pyarrow')\n",
    "        saved_files.append(parquet_filename)\n",
    "        print(f\"✅ Data cached to {parquet_filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Note: Parquet save skipped (not critical): {e}\")\n",
    "    \n",
    "    # Try pickle as backup\n",
    "    try:\n",
    "        pickle_filename = f\"{base_filename}.pkl\"\n",
    "        df.to_pickle(pickle_filename)\n",
    "        saved_files.append(pickle_filename)\n",
    "        print(f\"✅ Data pickled to {pickle_filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not save pickle: {e}\")\n",
    "    \n",
    "    return saved_files\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to fetch and cache Tesla data\"\"\"\n",
    "    \n",
    "    # Initialize fetcher\n",
    "    fetcher = TeslaDataFetcher()\n",
    "    \n",
    "    # Fetch all data\n",
    "    df = fetcher.combine_all_data()\n",
    "    \n",
    "    if not df.empty:\n",
    "        # Save with multiple formats\n",
    "        saved_files = save_dataframe(df, \"tesla_data_20251107\")\n",
    "        \n",
    "        # Display summary statistics\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"Data Summary\")\n",
    "        print(\"=\"*50)\n",
    "        print(f\"Total minute bars: {len(df)}\")\n",
    "        print(f\"Date range: {df['timestamp'].min()} to {df['timestamp'].max()}\")\n",
    "        print(f\"Average transactions per minute: {df['transactions'].mean():.0f}\")\n",
    "        print(f\"Average VIX level: {df['vix'].mean():.2f}\")\n",
    "        print(f\"Daily sentiment score: {df['sentiment_score'].iloc[0]:.3f}\")\n",
    "        \n",
    "        print(\"\\nFirst 5 rows of data:\")\n",
    "        print(df.head())\n",
    "        \n",
    "        print(\"\\nLast 5 rows of data:\")\n",
    "        print(df.tail())\n",
    "        \n",
    "        print(\"\\nData shape:\", df.shape)\n",
    "        print(\"\\nColumns:\", df.columns.tolist())\n",
    "        \n",
    "        # Calculate some useful metrics\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"Tesla Trading Metrics for the Day\")\n",
    "        print(\"=\"*50)\n",
    "        print(f\"Opening Price: ${df.iloc[0]['open']:.2f}\")\n",
    "        print(f\"Closing Price: ${df.iloc[-1]['close']:.2f}\")\n",
    "        print(f\"Day High: ${df['high'].max():.2f}\")\n",
    "        print(f\"Day Low: ${df['low'].min():.2f}\")\n",
    "        print(f\"Total Volume: {df['volume'].sum():,.0f}\")\n",
    "        print(f\"Total Transactions: {df['transactions'].sum():,.0f}\")\n",
    "        print(f\"VIX Range: {df['vix'].min():.2f} - {df['vix'].max():.2f}\")\n",
    "        print(f\"Sentiment Score: {df['sentiment_score'].iloc[0]:.3f} (scale: -1 to 1)\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"Files Saved:\")\n",
    "        print(\"=\"*50)\n",
    "        for file in saved_files:\n",
    "            print(f\"  - {file}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"❌ No data retrieved\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Function to load the cached data\n",
    "def load_cached_data(filename=\"tesla_data_20251107\"):\n",
    "    \"\"\"\n",
    "    Load cached data from file\n",
    "    \"\"\"\n",
    "    # Try different file formats\n",
    "    for ext in ['.csv', '.parquet', '.pkl']:\n",
    "        try:\n",
    "            file_path = f\"{filename}{ext}\"\n",
    "            if ext == '.csv':\n",
    "                df = pd.read_csv(file_path)\n",
    "                df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "            elif ext == '.parquet':\n",
    "                df = pd.read_parquet(file_path)\n",
    "                df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "            elif ext == '.pkl':\n",
    "                df = pd.read_pickle(file_path)\n",
    "            \n",
    "            print(f\"✅ Loaded data from {file_path}\")\n",
    "            return df\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"Warning loading {file_path}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(\"❌ No cached data found\")\n",
    "    return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the main function\n",
    "    df = main()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"DATA STRUCTURE FOR YOUR ML MODEL:\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"\"\"\n",
    "    Your DataFrame contains these features per minute:\n",
    "    \n",
    "    1. ticker: 'TSLA' (constant)\n",
    "    2. timestamp: DateTime for each minute\n",
    "    3. open: Opening price for that minute\n",
    "    4. high: High price for that minute\n",
    "    5. low: Low price for that minute\n",
    "    6. close: Closing price for that minute\n",
    "    7. volume: Trading volume for that minute\n",
    "    8. vwap: Volume-weighted average price\n",
    "    9. transactions: Number of trades in that minute\n",
    "    10. vix: Volatility index value at that minute\n",
    "    11. sentiment_score: Daily sentiment (-1 to 1, where 1 is very bullish)\n",
    "    \n",
    "    Perfect for your ensemble model with LightGBM/XGBoost + LSTM/GRU!\n",
    "    \"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
